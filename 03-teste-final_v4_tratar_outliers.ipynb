{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem: \n",
    "### Predicting whether a person with a given set of characteristics is likely to have a heart attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rosasampaio/Documents/github/data_science_prediction_pacient\n",
      "Columns: ['Age', 'Sex', 'ChestPainType', 'RestingBP', 'Cholesterol', 'FastingBS', 'RestingECG', 'MaxHR', 'ExerciseAngina', 'Oldpeak', 'ST_Slope', 'HeartDisease']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "!pwd\n",
    "df_raw = pd.read_csv(\"final-test/data/heart.csv\") \n",
    "print(\"Columns:\", df_raw.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
      "0   40   M           ATA        140          289          0     Normal    172   \n",
      "\n",
      "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
      "0              N      0.0       Up             0  \n",
      "Types :\n",
      " Age                 int64\n",
      "Sex                   str\n",
      "ChestPainType         str\n",
      "RestingBP           int64\n",
      "Cholesterol         int64\n",
      "FastingBS           int64\n",
      "RestingECG            str\n",
      "MaxHR               int64\n",
      "ExerciseAngina        str\n",
      "Oldpeak           float64\n",
      "ST_Slope              str\n",
      "HeartDisease        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.head(1))\n",
    "print(\"Types :\\n\",df_raw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Age    Sex  ChestPainType  RestingBP  Cholesterol  FastingBS  \\\n",
      "0    False  False          False      False        False      False   \n",
      "1    False  False          False      False        False      False   \n",
      "2    False  False          False      False        False      False   \n",
      "3    False  False          False      False        False      False   \n",
      "4    False  False          False      False        False      False   \n",
      "..     ...    ...            ...        ...          ...        ...   \n",
      "913  False  False          False      False        False      False   \n",
      "914  False  False          False      False        False      False   \n",
      "915  False  False          False      False        False      False   \n",
      "916  False  False          False      False        False      False   \n",
      "917  False  False          False      False        False      False   \n",
      "\n",
      "     RestingECG  MaxHR  ExerciseAngina  Oldpeak  ST_Slope  HeartDisease  \n",
      "0         False  False           False    False     False         False  \n",
      "1         False  False           False    False     False         False  \n",
      "2         False  False           False    False     False         False  \n",
      "3         False  False           False    False     False         False  \n",
      "4         False  False           False    False     False         False  \n",
      "..          ...    ...             ...      ...       ...           ...  \n",
      "913       False  False           False    False     False         False  \n",
      "914       False  False           False    False     False         False  \n",
      "915       False  False           False    False     False         False  \n",
      "916       False  False           False    False     False         False  \n",
      "917       False  False           False    False     False         False  \n",
      "\n",
      "[918 rows x 12 columns]\n",
      "SIZE:  918\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.isna())\n",
    "print(\"SIZE: \", len(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               918\n",
       "Sex               918\n",
       "ChestPainType     918\n",
       "RestingBP         918\n",
       "Cholesterol       918\n",
       "FastingBS         918\n",
       "RestingECG        918\n",
       "MaxHR             918\n",
       "ExerciseAngina    918\n",
       "Oldpeak           918\n",
       "ST_Slope          918\n",
       "HeartDisease      918\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same the df.shape[0]\n",
    "df_raw.isna().count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Sex               0\n",
       "ChestPainType     0\n",
       "RestingBP         0\n",
       "Cholesterol       0\n",
       "FastingBS         0\n",
       "RestingECG        0\n",
       "MaxHR             0\n",
       "ExerciseAngina    0\n",
       "Oldpeak           0\n",
       "ST_Slope          0\n",
       "HeartDisease      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado: não existens ausentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# Normalization\n",
    "# Apply StandardScaler ONLY to numeric columns.\n",
    "# And you should NEVER try to transform categorical columns to 0 and 1 before standardizing.\n",
    "# The same logic applies to OneHotEncoder (categorical columns ONLY)\n",
    "\n",
    "df_categorical = df_raw.select_dtypes(exclude=['number'])\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded = encoder.fit_transform(df_categorical)\n",
    "\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded,\n",
    "    columns=encoder.get_feature_names_out(df_categorical.columns),\n",
    "    index=df_raw.index\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers: Statistical Rule vs. Quality Rule (Domain Violation)\n",
    "Fundamental Difference (Very Important)\n",
    "\n",
    "## Statistical Outlier (IQR)\n",
    "- Extreme but plausible value\n",
    "- Ex.: Cholesterol = 450\n",
    "- Action: cap / flag / feature engineering\n",
    "\n",
    "## Domain Violation (Data Quality)\n",
    "- Impossible value in the real world\n",
    "- Ex.: Age = 200\n",
    "- Action: quality rule, not statistical\n",
    "\n",
    "*Age = 200 is not an outlier\n",
    "\n",
    "*Age = 200 is invalid data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treat outliers only in the original numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               int64\n",
       "RestingBP         int64\n",
       "Cholesterol       int64\n",
       "FastingBS         int64\n",
       "MaxHR             int64\n",
       "Oldpeak         float64\n",
       "HeartDisease      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_numeric = df_raw.select_dtypes(include=['number'])\n",
    "df_numeric.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RestingBP\n",
      "120    132\n",
      "130    118\n",
      "140    107\n",
      "110     58\n",
      "150     55\n",
      "      ... \n",
      "174      1\n",
      "117      1\n",
      "192      1\n",
      "129      1\n",
      "164      1\n",
      "Name: count, Length: 67, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_numeric[\"RestingBP\"].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastingBS\n",
      "0    704\n",
      "1    214\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_numeric[\"FastingBS\"].value_counts()) ## is a binary variable; statistical IQR does not apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age\n",
      "54    51\n",
      "58    42\n",
      "55    41\n",
      "56    38\n",
      "57    38\n",
      "52    36\n",
      "51    35\n",
      "59    35\n",
      "62    35\n",
      "53    33\n",
      "60    32\n",
      "48    31\n",
      "61    31\n",
      "63    30\n",
      "50    25\n",
      "43    24\n",
      "41    24\n",
      "46    24\n",
      "64    22\n",
      "49    21\n",
      "65    21\n",
      "44    19\n",
      "47    19\n",
      "45    18\n",
      "42    18\n",
      "38    16\n",
      "39    15\n",
      "67    15\n",
      "40    13\n",
      "66    13\n",
      "69    13\n",
      "37    11\n",
      "35    11\n",
      "68    10\n",
      "34     7\n",
      "74     7\n",
      "70     7\n",
      "36     6\n",
      "32     5\n",
      "71     5\n",
      "72     4\n",
      "29     3\n",
      "75     3\n",
      "31     2\n",
      "33     2\n",
      "77     2\n",
      "76     2\n",
      "28     1\n",
      "30     1\n",
      "73     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_numeric[\"Age\"].value_counts()) ## It is already numerical not to apply statistical IQR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do with these cases?\n",
    "\n",
    "It depends on the project's maturity:\n",
    "\n",
    "Option When to use Correct (cap at 120) legacy data Input few occurrences Delete critical error record Block ingestion from mature pipelines Create flag always recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"HeartDisease\"\n",
    "cols_numeric_features = [c for c in df_numeric.columns if c != target_col]\n",
    "\n",
    "df_outliers = df_numeric.drop(columns=[\"HeartDisease\"],  errors=\"ignore\")\n",
    "\n",
    "# automatically detects binary characters (e.g., 0/1)\n",
    "binary_cols = [c for c in cols_numeric_features if df_outliers[c].dropna().nunique() <= 2] \n",
    "\n",
    "# continuous (where IQR makes sense)\n",
    "cols_iqr = [c for c in cols_numeric_features if c not in binary_cols and c not in ['Age']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" OLD check outliers statistic \"\"\"\n",
    "\n",
    "for col in df_outliers.columns:\n",
    "    Q1 = df_raw[col].quantile(0.25)\n",
    "    Q3 = df_raw[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df_raw[(df_raw[col] < lower) | (df_raw[col] > upper)][col]\n",
    "    print(f\"{col}: {len(outliers)} outliers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']\n"
     ]
    }
   ],
   "source": [
    "print(cols_iqr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" NEW FUNCTION OUTLIERS \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def iqr_cap_with_flag(df, cols, k=1.5):\n",
    "    df2 = df_outliers.copy()\n",
    "    limits = {}\n",
    "\n",
    "    for col in cols:\n",
    "        q1 = df2[col].quantile(0.25)\n",
    "        q3 = df2[col].quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "        low = q1 - k * iqr\n",
    "        high = q3 + k * iqr\n",
    "\n",
    "        limits[col] = (low, high)\n",
    "\n",
    "        df2[f\"{col}_outlier_flag\"] = ((df2[col] < low) | (df2[col] > high)).astype(int)\n",
    "        df2[f\"{col}_capped\"] = df2[col].clip(lower=low, upper=high)\n",
    "\n",
    "    return df2, limits\n",
    "\n",
    "\n",
    "\n",
    "df_numeric_treated, iqr_limits = iqr_cap_with_flag(df_outliers, cols=cols_iqr, k=1.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric_treated.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# df_numeric_treated\n",
    "\n",
    "Interpretação de maturidade (nível alto)\n",
    "O teu dataset agora separa claramente:\n",
    "| Tipo     | Exemplo     | Tratamento       |\n",
    "| -------- | ----------- | ---------------- |\n",
    "| Domínio  | Age         | regra de negócio |\n",
    "| Binário  | FastingBS   | validação lógica |\n",
    "| Contínuo | Cholesterol | IQR + cap + flag |\n",
    "\n",
    "Isso é Data Quality + Feature Engineering, não só ML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatena todas as variáveis\n",
    "df_encoded = pd.concat([df_numeric_treated, encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check\n",
    "df_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.isna().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adiciona/volta a variável target\n",
    "df_encoded[\"HeartDisease\"] = df_raw[\"HeartDisease\"]\n",
    "df_encoded.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded[\"HeartDisease\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificação de outliers com IQR\n",
    "\n",
    "IQR = Q3 – Q1\n",
    "Onde:\n",
    "Q1 = 25º percentil\n",
    "Q3 = 75º percentil\n",
    "\n",
    "Um valor é considerado outlier se estiver fora de: [ Q1 - 1.5*IQR ,  Q3 + 1.5*IQR ]\n",
    "\n",
    "Regra importante\n",
    "Outliers só fazem sentido para:\n",
    "\n",
    "variáveis numéricas contínuas originais\n",
    "❌ Nunca para colunas one-hot (0/1)\n",
    "❌ Nunca para o target\n",
    "\n",
    "Resumo mental (importante)\n",
    "✔️ df_encoded é o DataFrame certo\n",
    "✔️ Outliers só nas contínuas reais\n",
    "❌ Não aplicar IQR em one-hot\n",
    "❌ Não aplicar IQR no target\n",
    "✔️ Guardar iqr_limits para produção\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Técnica -> RestingBP\n",
    "Vou usar o padrão mais recomendado: Winsorization (cap) + flag apenas para colunas numéricas contínuas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_encoded[\"RestingBP\"].value_counts()) ### aplicado na função: iqr_cap_with_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_encoded[\"Cholesterol\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_encoded[\"MaxHR\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_encoded[\"Oldpeak\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIM da análise de Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~Remove Outliers~~ tratamos os outliers em colunas originas númericas e não binárias\n",
    "Remover outliers reduz linhas do dataset, se fizer isso para muitas colunas e tiver IQR estreito, pode perder muitos dados. Alternativa: substituir outliers por mediana ou limites, por exemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_clean)) ## old ficaram 587 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_encoded)) # manteve 918 linhas mesmo tamanho de df_raw OK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nao executado depois o tratamento do outliers, apenas check do antes e depois \n",
    "# check total record: ANTES DE TRATAR OS OUTLIERS\n",
    "print(\"Total: \",df.shape[0],\"Total sem outliers: \", df_clean.shape[0])\n",
    "reduzidos = df.shape[0] - df_clean.shape[0]\n",
    "print(f'Foram reduzidos o total de {reduzidos}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separar os dados em treino/teste com stratificação. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "y = df_encoded[\"HeartDisease\"]\n",
    "X = df_encoded\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar somente colunas numéricas\n",
    "numeric_cols = X_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicar um modelo K-Nearest Neighbors (KNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliar o modelo com:\n",
    " - Matriz de confusão\n",
    " - o Acurácia, Precisão, Revocação e F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# predict: previsões com os dados de teste\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")    \n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explicação:\n",
    "TN (True Negative): O modelo previu 0 e o rótulo real era 0 → previsão correta de negativo.\n",
    "\n",
    "FN (False Negative): O modelo previu 0 mas o rótulo real era 1 → \"falha na deteção\".\n",
    "\n",
    "FP (False Positive): O modelo previu 1 mas o rótulo real era 0 → \"falso alarme\".\n",
    "\n",
    "TP (True Positive): O modelo previu 1 e o rótulo real era 1 → previsão correta de positivo.\n",
    "\n",
    "\n",
    "| Real \\ Previsto | 0 (Previsto) | 1 (Previsto) |\n",
    "|-----------------|--------------|--------------|\n",
    "| 0 (Real)        | TN           | FP           |\n",
    "| 1 (Real)        | FN           | TP           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de Confusão:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRelatório de Classificação:\\n\" , classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPLICAÇÃO 1\n",
    "### Após oneHotEnconder\n",
    "### Apenas com as variáveis numericas\n",
    "\n",
    "# Análise de KNN (baseado no pdf 06-FT03)\n",
    "``` knn = KNeighborsClassifier(n_neighbors=5) ```\n",
    "\n",
    "Na primeira aplicação com hiper parametros padrão e número de clusters igual 5, obtivemos:\n",
    "\n",
    "**Total da amostra: 918 rows (100%)**\n",
    "\n",
    "- TN (True Negative): 76% \n",
    "- FP (False Positive): 6% \n",
    "- FN (False Negative): 3% \n",
    "- TP (True Positive): 99% \n",
    "\n",
    "\n",
    "Ou seja mais de 175% do total de TN + TP (76% TN + 99% TP) do nosso modelo treinou corretamente.\n",
    "\n",
    "Em contra partida, tivemos 3(FN) linhas da amostra classificado incorretamente, no caso do problema em questão pode ser fatal, vamos considerar como falha na deteção da doença(FN), pelo modelo.\n",
    "\n",
    "Como ponto de melhoria: diminuir os 'False Negative'.\n",
    "\n",
    "* Com relação a outras métricas:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Accuracy: obtivemos *0.936*, podemos considerar ótimo para o modelo conseguiu predizer 94% dos casos na amostra, porém é importante ajustar para conseguir adicionar os 3% (FN) restantes como TP.\n",
    "\n",
    "Melhores parâmetros: {'knn__metric': 'manhattan', **'knn__n_neighbors': 11**, 'knn__weights': 'distance'}\n",
    "Melhor accuracy (validação): 0.936 \n",
    "Accuracy no teste: 0.951\n",
    "\n",
    "\n",
    "\n",
    "| Classe | Precision | Recall | F1-score | Support |\n",
    "|--------|-----------|--------|----------|---------|\n",
    "| 0      | 0.96      | 0.93   | 0.94     | 82      |\n",
    "| 1      | 0.94      | 0.97   | 0.96     | 102     |\n",
    "| **Accuracy** |           |        | **0.95** | 184     |\n",
    "| **Macro avg** | 0.95      | 0.95   | 0.95     | 184     |\n",
    "| **Weighted avg** | 0.95      | 0.95   | 0.95     | 184     |\n",
    "\n",
    "Pessoas saudáveis:\n",
    "2. Na Precisão de positivos e está certo tivemos 96%, dentre os quais 4% estão classificados com imprecisão, não tem 100% de 'certeza', como 0 (podem ou não estarem saudáveis), neste caso foram marcados como saudáveis mas podem ser que estejam <u>doentes</u>.\n",
    "\n",
    "3. recall\n",
    "Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos)\n",
    "O que significa que todos os exemplos que realmente eram classe 0, pessoas saudáveis, o modelo conseguiu identificar 93%. deixando apenas 7% como falsos saudáveis.\n",
    "\n",
    "4. F-score\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "o que significa que essa métrica mede o equilíbrio. Evita que um modelo com recall alto e precision baixa (ou vice-versa) pareça bom.\n",
    "em resumo, precisamos ter as duas métricas balanceadas para de facto ter um modelo com boa predição.\n",
    "f.Score = 94% e recall = 93% (temos equilíbrio)\n",
    "\n",
    "Médias:\n",
    "Macro Avg = 0.95 pode representar um modelo optimo.\n",
    "Weighted Avg = 0.95, semelhante a accuracy, logo, podemos dizer que as classes estão balanceadas entre elas.\n",
    "➡️ Se weighted = accuracy, normalmente as classes não estão muito desbalanceadas.\n",
    "Weighted Avg  =  95% e comparanco com a accuracy = 94% (temos balanceamanto)\n",
    "\n",
    "conclusão\n",
    "Encrontramos um ponto crítico de possível melhoria para o futuro:\n",
    "\n",
    "1. Ponto crítico de melhoria, para os recall em classe de pessoas doentes, positivas para ataque. tivemos recall = 94%, ou seja deixou de predizer corretamente 6% dos doentes, o que pode ser fatal. \n",
    "\n",
    "1.1 Sugestão de solução: melhorar o balanceamento de pessoas doentes (foi feito, aplicamos o OneHotEncoder), ou seja, aumentar a quantidade de doentes na amostra de treinamento do modelo. Já para deixar os padrões de pessoas doentes, precisamos confirmar se temos mais atributos que podem explicam melhor a classe 1(pessoas doentes).   DONE \n",
    "1.2 Tratamos os outlires com as técnicas de  flags, tratamos apenas variáveis numéricas originas no df_raw e não binárias. DONE \n",
    "\n",
    "resultado: após melhorias 1.1 e 1.2 os TP subiram para 99% de detecção. sugestão para nova aplicação do KNN será com 11 K."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~EXPLICAÇÃO 2~~ antes do onhotencode\n",
    "### Antes oneHotEnconder\n",
    "### Com as variáveis numericas + categorical transformadas em numericas com OneHotEncoder\n",
    "# Análise de KNN (baseado no pdf 06-FT03)\n",
    "``` knn = KNeighborsClassifier(n_neighbors=5) ```\n",
    "\n",
    "Na primeira aplicação com hiper parametros padrão e número de clusters igual 5, obtivemos:\n",
    "TP (True Positive): 59 do total de 587 amostras\n",
    "TN (True Negative): 16 do total de 587 amostras\n",
    "FP (False Positive): 19 do total de 587 amostras\n",
    "FN (False Negative): 31 do total de 587 amostras\n",
    "\n",
    "ou seja mais de 50% do nosso modelo treinou corretamente. Em contra partida, tivemos 31 linhas da amostra classificado incorretamente, no caso do problema em questão pode ser fatal, vamos considerar como falha na deteção da doença pelo modelo.\n",
    "\n",
    "Com relação a outras métricas:\n",
    "1. Accuracy: obtivemos *0.755*, podemos considerar  bom para o modelo conseguiu predizer 70 % dos casos na amostra, porém é importate ajustar para conseguir adicionar os 30% restantes como TP.\n",
    "Melhor accuracy (validação): 0.755 \n",
    "Accuracy no teste: 0.703\n",
    "\n",
    "Pessoas saudáveis:\n",
    "\n",
    "| Classe        | Precision | Recall | F1-Score | Support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| **0**         | 0.73      | 0.76   | 0.75     | 68      |\n",
    "| **1**         | 0.66      | 0.62   | 0.64     | 50      |\n",
    "| **Accuracy**  | —         | —      | 0.70     | 118     |\n",
    "| **Macro Avg** | 0.70      | 0.69   | 0.69     | 118     |\n",
    "| **Weighted Avg** | 0.70  | 0.70   | 0.70     | 118     |\n",
    "\n",
    "\n",
    "2. Na Precisão de posotivos e está certo tivemos 73 %\n",
    "\n",
    "3. recall\n",
    "Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos)\n",
    "O que significa que todos os exemplos que realmente eram classe 0, pessoas saudáveis, o modelo conseguiu identificar 76%. deixando apenas 24% como falsos doentes.\n",
    "\n",
    "4. F-score\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "o que significa que essa métrica mede o equilíbrio. Evita que um modelo com recall alto e precision baixa (ou vice-versa) pareça bom.\n",
    "em resumo, precisamos ter as duas métricas balanceadas para de facto ter um modelo com boa predição.\n",
    "\n",
    "Médias:\n",
    "Macro Avg = 0.69 pode representar um modelo moderado.\n",
    "Weighted Avg = 0.70, semelhante a accuracy, logo, podemos dizer que as classes estão balanceadas entre elas.\n",
    "➡️ Se weighted = accuracy, normalmente as classes não estão muito desbalanceadas.\n",
    "\n",
    "conclusão\n",
    "Encrontramos um ponto crítico de possível melhoria para futura:\n",
    "\n",
    "1. Ponto crítico de melhoria, para os recall em classe de pessoas doentes, positivas para ataque. tivemos recall = 62& ou seja deixou de predizer corretamente 38% dos doentes, o que pode ser fatal. \n",
    "1.1 Sugestão de solução: melhorar o balanceamento de pessoas doentes, ou seja, aumentar a quantidade de doentes na amostra de treinamento do modelo. Já para deixar os padrões de pessoas doentes, precisamos confirmar se temos mais atributos que podem explicam melhor a classe 1(pessoas doentes).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimizar o número de vizinhos com GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Hiper parametros\n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"knn__metric\": [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "# otimização de vizinhos\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid.best_params_)\n",
    "print(f\"Melhor accuracy (validação): {grid.best_score_:.3f} \")\n",
    "\n",
    "# best_model = grid.best_estimator_\n",
    "# y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# accuracy_score: percentagem de classificações corretas\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy no teste: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparar o desempenho antes e depois da otimização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de KNN (baseado no pdf 06-FT03)\n",
    "## knowledge\n",
    "``` knn = KNeighborsClassifier(n_neighbors=5) ```\n",
    "\n",
    "Na primeira aplicação com hiper parametros padrão e número de clusters igual 5, obtivemos:\n",
    "TP (True Positive): 59 do total de 587 amostras\n",
    "TN (True Negative): 16 do total de 587 amostras\n",
    "FP (False Positive): 19 do total de 587 amostras\n",
    "FN (False Negative): 31 do total de 587 amostras\n",
    "\n",
    "ou seja mais de 50% do nosso modelo treinou corretamente. Em contra partida, tivemos 31 linhas da amostra classificado incorretamente, no caso do problema em questão pode ser fatal, vamos considerar como falha na deteção da doença pelo modelo.\n",
    "\n",
    "Com relação a outras métricas:\n",
    "1. Accuracy: obtivemos *0.755*, podemos considerar  bom para o modelo conseguiu predizer 70 % dos casos na amostra, porém é importate ajustar para conseguir adicionar os 30% restantes como TP.\n",
    "\n",
    "Pessoas saudáveis:\n",
    "2. Na Precisão de posotivos e está certo tivemos 73 %\n",
    "\n",
    "3. recall\n",
    "Recall = Verdadeiros Positivos / (Verdadeiros Positivos + Falsos Negativos)\n",
    "O que significa que todos os exemplos que realmente eram classe 0, pessoas saudáveis, o modelo conseguiu identificar 76%. deixando apenas 24% como falsos doentes.\n",
    "\n",
    "4. F-score\n",
    "F1 = 2 * (precision * recall) / (precision + recall)\n",
    "o que significa que essa métrica mede o equilíbrio. Evita que um modelo com recall alto e precision baixa (ou vice-versa) pareça bom.\n",
    "em resumo, precisamos ter as duas métricas balanceadas para de facto ter um modelo com boa predição.\n",
    "\n",
    "Médias:\n",
    "Macro Avg = 0.69 pode representar um modelo moderado.\n",
    "Weighted Avg = 0.70, semelhante a accuracy, logo, podemos dizer que as classes estão balanceadas entre elas.\n",
    "➡️ Se weighted = accuracy, normalmente as classes não estão muito desbalanceadas.\n",
    "\n",
    "conclusão\n",
    "Encrontramos um ponto crítico de possível melhoria para futura:\n",
    "\n",
    "1. Ponto crítico de melhoria, para os recall em classe de pessoas doentes, positivas para ataque. tivemos recall = 62& ou seja deixou de predizer corretamente 38% dos doentes, o que pode ser fatal. \n",
    "1.1 Sugestão de solução: melhorar o balanceamento de pessoas doentes, ou seja, aumentar a quantidade de doentes na amostra de treinamento do modelo. Já para deixar os padrões de pessoas doentes, precisamos confirmar se temos mais atributos que podem explicam melhor a classe 1(pessoas doentes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTEXTO PARA explicação:\n",
    "TP (True Positive): O modelo previu 1 e o rótulo real era 1 → previsão correta de positivo.\n",
    "\n",
    "TN (True Negative): O modelo previu 0 e o rótulo real era 0 → previsão correta de negativo.\n",
    "\n",
    "FP (False Positive): O modelo previu 1 mas o rótulo real era 0 → \"falso alarme\".\n",
    "\n",
    "FN (False Negative): O modelo previu 0 mas o rótulo real era 1 → \"falha na deteção\".\n",
    "\n",
    "\n",
    "| Real \\ Previsto | 0 (Previsto) | 1 (Previsto) |\n",
    "|-----------------|--------------|--------------|\n",
    "| 0 (Real)        | TN           | FP           |\n",
    "| 1 (Real)        | FN           | TP           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resultado do classification_report\n",
    "Relatório de Classificação:\n",
    "\n",
    "classe 0 => Saudável (falso)\n",
    "\n",
    "classe 1 => doente (positivo)\n",
    "\n",
    "# Sem oneHotEncoder\n",
    "\n",
    "| Classe        | Precision | Recall | F1-Score | Support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| **0**         | 0.73      | 0.76   | 0.75     | 68      |\n",
    "| **1**         | 0.66      | 0.62   | 0.64     | 50      |\n",
    "| **Accuracy**  | —         | —      | 0.70     | 118     |\n",
    "| **Macro Avg** | 0.70      | 0.69   | 0.69     | 118     |\n",
    "| **Weighted Avg** | 0.70  | 0.70   | 0.70     | 118     |\n",
    "\n",
    "\n",
    "# Com oneHotEncoder\n",
    "| Classe        | Precision | Recall | F1-Score | Support |\n",
    "|---------------|-----------|--------|----------|---------|\n",
    "| **0**         | 0.97      | 0.87   | 0.91     | 68      |\n",
    "| **1**         | 0.84      | 0.96   | 0.90     | 50      |\n",
    "| **Accuracy**  | —         | —      | 0.91     | 118     |\n",
    "| **Macro Avg** | 0.90      | 0.91   | 0.91     | 118     |\n",
    "| **Weighted Avg** | 0.91  | 0.91   | 0.91     | 118     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prever a condição de um novo paciente\n",
    "*com valores fictícios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendendo os campos:\n",
    "| Campo           | Descrição                                                    | Exemplo | Tipo        | Por extenso / Significado                                  |\n",
    "|-----------------|--------------------------------------------------------------|---------|-------------|-------------------------------------------------------------|\n",
    "| Age             | Idade do paciente                                            | 55      | numérica    | 55 anos                                                     |\n",
    "| Sex             | Sexo do paciente                                             | M       | categórica  | M = masculino, F = feminino                                 |\n",
    "| ChestPainType   | Tipo de dor no peito                                         | ATA     | categórica  | ATA = angina atípica; ASY = assintomático; TA = típica; NAP = não anginosa |\n",
    "| RestingBP       | Pressão arterial em repouso (mm Hg)                           | 130     | numérica    | 130 mm Hg                                                   |\n",
    "| Cholesterol     | Colesterol sérico total (mg/dl)                               | 245     | numérica    | 245 mg/dl                                                   |\n",
    "| FastingBS       | Glicemia em jejum > 120 mg/dl?                                | 0       | categórica  | 0 = normal; 1 = alta (acima de 120 mg/dl)                   |\n",
    "| RestingECG      | Resultado do eletrocardiograma em repouso                     | ST      | categórica  | Normal / Anomalia ST-T / Hipertrofia Ventricular Esquerda  |\n",
    "| MaxHR           | Frequência cardíaca máxima atingida                           | 150     | numérica    | 150 bpm                                                     |\n",
    "| ExerciseAngina  | Angina induzida por exercício                                 | N       | categórica  | N = não apresentou; Y = apresentou angina                   |\n",
    "| Oldpeak         | Depressão do segmento ST por exercício                        | 1.0     | numérica    | Depressão ST de 1.0 mm                                      |\n",
    "| ST_Slope        | Inclinação do segmento ST no pico do exercício                | Down    | categórica  | Up = subida; Flat = plano; Down = descida                   |\n",
    "| HeartDisease    | Presença de doença cardíaca (TARGET)                          | 1       | categórica  | 1 = possui doença cardíaca; 0 = não possui                  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaplicar o modelo filtrando as colunas originais e usando as colunas tratadas dos outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knowledge\n",
    "* Entre pessoas experientes em Data Stewardship (com foco em governança + explicabilidade + robustez), a opção mais recomendada costuma ser:\n",
    "\n",
    "✅ Usar _capped + _outlier_flag e NÃO usar as colunas originais (não capped) no modelo.\n",
    "(equivalente à tua Opção A, mas “sem duplicar” a mesma variável duas vezes.)\n",
    "\n",
    "Por quê essa é a mais defendida?\n",
    "\n",
    "- Robustez: o modelo não “explode” por valores extremos.\n",
    "- Explicabilidade: a flag diz claramente “esse caso era extremo”.\n",
    "- Governança: fica transparente o que foi tratado e quando (útil para auditoria e stakeholders).\n",
    "- Menos ruído: evitar manter original + capped juntos reduz colinearidade e confusão na interpretação.\n",
    "\n",
    "Quando eu NÃO recomendaria essa opção?\n",
    "- Se o outlier é um evento raro porém super informativo (ex.: fraude, picos reais) e você quer que o modelo “sinta” a magnitude total. Aí você pode manter o original também — mas isso é uma decisão consciente, não padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recomendado: usar _capped + _outlier_flag e remover as colunas originais contínuas\n",
    "target = \"HeartDisease\"\n",
    "orig_continuous = [\"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]\n",
    "\n",
    "capped_cols = [c for c in df_encoded.columns if c.endswith(\"_capped\")]\n",
    "flag_cols  = [c for c in df_encoded.columns if c.endswith(\"_outlier_flag\")]\n",
    "\n",
    "# base = tudo que não é target, não é original contínua, não é capped/flag\n",
    "base_cols = [\n",
    "    c for c in df_encoded.columns\n",
    "    if c != target\n",
    "    and c not in orig_continuous\n",
    "    and not c.endswith(\"_capped\")\n",
    "    and not c.endswith(\"_outlier_flag\")\n",
    "]\n",
    "\n",
    "X = df_encoded[base_cols + capped_cols + flag_cols]\n",
    "y = df_encoded[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=11)\n",
    "knn.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificação \n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict: previsões com os dados de teste\n",
    "y_pred = knn.predict(X_test_scaled)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")    \n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Real \\ Previsto | 0 (Previsto) | 1 (Previsto) |\n",
    "|-----------------|--------------|--------------|\n",
    "| 0 (Real)        | TN           | FP           |\n",
    "| 1 (Real)        | FN           | TP           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Matriz de Confusão:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRelatório de Classificação:\\n\" , classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTIMIZAÇÃO GRID SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Hiper parametros\n",
    "param_grid = {\n",
    "    \"knn__n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"],\n",
    "    \"knn__metric\": [\"euclidean\", \"manhattan\"]\n",
    "}\n",
    "\n",
    "# otimização de vizinhos\n",
    "grid = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Melhores parâmetros:\", grid.best_params_)\n",
    "print(f\"Melhor accuracy (validação): {grid.best_score_:.3f} \")\n",
    "\n",
    "# best_model = grid.best_estimator_\n",
    "# y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# accuracy_score: percentagem de classificações corretas\n",
    "test_acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy no teste: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOVA PREDIÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 0) Novo paciente (formato original)\n",
    "novo_paciente = pd.DataFrame([{\n",
    "    \"Age\": 58,\n",
    "    \"Sex\": \"M\",\n",
    "    \"ChestPainType\": \"ATA\",\n",
    "    \"RestingBP\": 138,\n",
    "    \"Cholesterol\": 240,\n",
    "    \"FastingBS\": 0,\n",
    "    \"RestingECG\": \"ST\",\n",
    "    \"MaxHR\": 160,\n",
    "    \"ExerciseAngina\": \"N\",\n",
    "    \"Oldpeak\": 1.4,\n",
    "    \"ST_Slope\": \"Flat\"\n",
    "}])\n",
    "\n",
    "\n",
    "# 1) One-hot encoding (usar o MESMO encoder já fitado)\n",
    "df_categorical = novo_paciente.select_dtypes(exclude=[\"number\"])\n",
    "encoded_arr = encoder.transform(df_categorical)\n",
    "\n",
    "encoded_df_new = pd.DataFrame(\n",
    "    encoded_arr,\n",
    "    columns=encoder.get_feature_names_out(df_categorical.columns),\n",
    "    index=novo_paciente.index\n",
    ")\n",
    "\n",
    "\n",
    "# 2) Numéricas + capped/flags (usar os MESMOS limites iqr_limits do treino)\n",
    "df_numeric = novo_paciente.select_dtypes(include=[\"number\"]).copy()\n",
    "\n",
    "for col in [\"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]:\n",
    "    low, high = iqr_limits[col]\n",
    "    df_numeric[f\"{col}_outlier_flag\"] = ((df_numeric[col] < low) | (df_numeric[col] > high)).astype(int)\n",
    "    df_numeric[f\"{col}_capped\"] = df_numeric[col].clip(lower=low, upper=high)\n",
    "\n",
    "df_numeric_final = df_numeric[[\n",
    "    \"Age\", \"FastingBS\",\n",
    "    \"RestingBP_capped\", \"Cholesterol_capped\", \"MaxHR_capped\", \"Oldpeak_capped\",\n",
    "    \"RestingBP_outlier_flag\", \"Cholesterol_outlier_flag\", \"MaxHR_outlier_flag\", \"Oldpeak_outlier_flag\"\n",
    "]]\n",
    "\n",
    "\n",
    "# 3) Montar X do novo paciente e alinhar com as colunas do treino\n",
    "novo_X = pd.concat([df_numeric_final, encoded_df_new], axis=1)\n",
    "\n",
    "# alinhar com as colunas que o modelo espera (X_train.columns)\n",
    "novo_X = novo_X.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "\n",
    "# 4) Escalar com o MESMO scaler (alinhar com as colunas do scaler)\n",
    "if hasattr(scaler, \"feature_names_in_\"):\n",
    "    cols_scaler = list(scaler.feature_names_in_)\n",
    "else:\n",
    "    cols_scaler = list(X_train.columns)  # fallback: use a ordem do treino\n",
    "\n",
    "novo_X_for_scaler = novo_X.reindex(columns=cols_scaler, fill_value=0)\n",
    "novo_X_scaled = scaler.transform(novo_X_for_scaler)\n",
    "\n",
    "\n",
    "# 5) Predição com o modelo treinado (GridSearchCV)\n",
    "pred_novo = grid.predict(novo_X_scaled)\n",
    "\n",
    "print(pred_novo[0])\n",
    "print(f\"Risco previsto: {'Doente' if pred_novo[0] == 1 else 'Saudável'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
